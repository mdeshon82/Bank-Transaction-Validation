{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV files\n",
    "transactions = pd.read_csv('Data/transactions.csv')\n",
    "account_holders = pd.read_excel('Data/account_holders.xlsx')\n",
    "\n",
    "# Load data from APIs\n",
    "import requests\n",
    "\n",
    "def fetch_exchange_rates(api_key):\n",
    "    url = f'https://openexchangerates.org/api/latest.json?app_id={api_key}'\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "def fetch_market_data(api_key, symbol):\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "exchange_rates = fetch_exchange_rates('your_exchange_rates_api_key')\n",
    "market_data = fetch_market_data('your_alpha_vantage_api_key', 'AAPL')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning and Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "transactions.dropna(inplace=True)\n",
    "account_holders.dropna(inplace=True)\n",
    "\n",
    "# Correcting data types\n",
    "transactions['transaction_date'] = pd.to_datetime(transactions['transaction_date'])\n",
    "account_holders['account_creation_date'] = pd.to_datetime(account_holders['account_creation_date'])\n",
    "\n",
    "# Merging datasets\n",
    "merged_data = pd.merge(transactions, account_holders, on='account_id', how='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating New Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average transaction amount and transaction frequency\n",
    "merged_data['avg_transaction_amount'] = merged_data.groupby('account_id')['transaction_amount'].transform('mean')\n",
    "merged_data['transaction_frequency'] = merged_data.groupby('account_id')['transaction_id'].transform('count')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store Clean Data in SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to SQLite database (or create it if it doesn't exist)\n",
    "db_path = 'Data/fraud_detection.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Save the cleaned DataFrame to a SQLite table\n",
    "merged_data.to_sql('transactions', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "print(f\"Database created and stored at {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying Data from SQLite for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconnect to the SQLite database\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Define SQL queries\n",
    "query_trend = \"\"\"\n",
    "SELECT transaction_date, SUM(transaction_amount) as total_amount\n",
    "FROM transactions\n",
    "GROUP BY transaction_date\n",
    "ORDER BY transaction_date;\n",
    "\"\"\"\n",
    "\n",
    "query_account_comparison = \"\"\"\n",
    "SELECT account_id, SUM(transaction_amount) as total_amount\n",
    "FROM transactions\n",
    "GROUP BY account_id\n",
    "ORDER BY total_amount DESC;\n",
    "\"\"\"\n",
    "\n",
    "query_correlation = \"\"\"\n",
    "SELECT transaction_frequency, avg_transaction_amount\n",
    "FROM transactions;\n",
    "\"\"\"\n",
    "\n",
    "# Execute queries and store results in DataFrames\n",
    "trend_data = pd.read_sql_query(query_trend, conn)\n",
    "account_comparison_data = pd.read_sql_query(query_account_comparison, conn)\n",
    "correlation_data = pd.read_sql_query(query_correlation, conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiziing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Line plot for transaction trends over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=trend_data, x='transaction_date', y='total_amount')\n",
    "plt.title('Transaction Trends Over Time')\n",
    "plt.show()\n",
    "\n",
    "# Bar chart comparing transaction amounts by account\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=account_comparison_data, x='account_id', y='total_amount')\n",
    "plt.title('Transaction Amounts by Account')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot showing the correlation between transaction frequency and amount\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=correlation_data, x='transaction_frequency', y='avg_transaction_amount')\n",
    "plt.title('Correlation between Transaction Frequency and Amount')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output To CSV for Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_data.to_csv('Data/Out/trend_data.csv', index=False)\n",
    "account_comparison_data.to_csv('Data/Out/account_comparison_data.csv', index=False)\n",
    "correlation_data.to_csv('Data/Out/correlation_data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestDataCleaning(unittest.TestCase):\n",
    "    def test_dropna(self):\n",
    "        data = pd.DataFrame({'A': [1, 2, None], 'B': [4, None, 6]})\n",
    "        cleaned_data = data.dropna()\n",
    "        self.assertEqual(cleaned_data.shape[0], 1)\n",
    "    \n",
    "    def test_correct_data_type(self):\n",
    "        data = pd.DataFrame({'date': ['2021-01-01', '2021-01-02']})\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        self.assertTrue(pd.api.types.is_datetime64_any_dtype(data['date']))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
